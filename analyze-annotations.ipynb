{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53ebc1de-431b-4e85-96f8-c5fd0c967159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import srsly\n",
    "from pathlib import Path\n",
    "import polars as pl\n",
    "from lazylines import LazyLines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744fc124-21ed-4065-96cd-fee850971337",
   "metadata": {},
   "source": [
    "This is a polars dataframe with all the annotations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7819ce-0b78-41e0-957e-99d0677a6f63",
   "metadata": {},
   "source": [
    "## Google Emotions Dataset\n",
    "\n",
    "Small warning: this is Reddit data. We can't expect texts of people that behave nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e70d8b18-fdae-43d8-bc46-4dae0b9dbfde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 37)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>text</th><th>id</th><th>author</th><th>subreddit</th><th>link_id</th><th>parent_id</th><th>created_utc</th><th>rater_id</th><th>example_very_unclear</th><th>admiration</th><th>amusement</th><th>anger</th><th>annoyance</th><th>approval</th><th>caring</th><th>confusion</th><th>curiosity</th><th>desire</th><th>disappointment</th><th>disapproval</th><th>disgust</th><th>embarrassment</th><th>excitement</th><th>fear</th><th>gratitude</th><th>grief</th><th>joy</th><th>love</th><th>nervousness</th><th>optimism</th><th>pride</th><th>realization</th><th>relief</th><th>remorse</th><th>sadness</th><th>surprise</th><th>neutral</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>i64</td><td>bool</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;That game hurt…</td><td>&quot;eew5j0j&quot;</td><td>&quot;Brdd9&quot;</td><td>&quot;nrl&quot;</td><td>&quot;t3_ajis4z&quot;</td><td>&quot;t1_eew18eq&quot;</td><td>1.5484e9</td><td>1</td><td>false</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td></tr><tr><td>&quot; &gt;sexuality sh…</td><td>&quot;eemcysk&quot;</td><td>&quot;TheGreen888&quot;</td><td>&quot;unpopularopini…</td><td>&quot;t3_ai4q37&quot;</td><td>&quot;t3_ai4q37&quot;</td><td>1.5481e9</td><td>37</td><td>true</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>&quot;You do right, …</td><td>&quot;ed2mah1&quot;</td><td>&quot;Labalool&quot;</td><td>&quot;confessions&quot;</td><td>&quot;t3_abru74&quot;</td><td>&quot;t1_ed2m7g7&quot;</td><td>1.5464e9</td><td>37</td><td>false</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 37)\n",
       "┌──────────────┬─────────┬─────────────┬──────────────┬───┬─────────┬─────────┬──────────┬─────────┐\n",
       "│ text         ┆ id      ┆ author      ┆ subreddit    ┆ … ┆ remorse ┆ sadness ┆ surprise ┆ neutral │\n",
       "│ ---          ┆ ---     ┆ ---         ┆ ---          ┆   ┆ ---     ┆ ---     ┆ ---      ┆ ---     │\n",
       "│ str          ┆ str     ┆ str         ┆ str          ┆   ┆ i64     ┆ i64     ┆ i64      ┆ i64     │\n",
       "╞══════════════╪═════════╪═════════════╪══════════════╪═══╪═════════╪═════════╪══════════╪═════════╡\n",
       "│ That game    ┆ eew5j0j ┆ Brdd9       ┆ nrl          ┆ … ┆ 0       ┆ 1       ┆ 0        ┆ 0       │\n",
       "│ hurt.        ┆         ┆             ┆              ┆   ┆         ┆         ┆          ┆         │\n",
       "│ >sexuality   ┆ eemcysk ┆ TheGreen888 ┆ unpopularopi ┆ … ┆ 0       ┆ 0       ┆ 0        ┆ 0       │\n",
       "│ shouldn’t be ┆         ┆             ┆ nion         ┆   ┆         ┆         ┆          ┆         │\n",
       "│ a group…     ┆         ┆             ┆              ┆   ┆         ┆         ┆          ┆         │\n",
       "│ You do       ┆ ed2mah1 ┆ Labalool    ┆ confessions  ┆ … ┆ 0       ┆ 0       ┆ 0        ┆ 1       │\n",
       "│ right, if    ┆         ┆             ┆              ┆   ┆         ┆         ┆          ┆         │\n",
       "│ you don't    ┆         ┆             ┆              ┆   ┆         ┆         ┆          ┆         │\n",
       "│ care …       ┆         ┆             ┆              ┆   ┆         ┆         ┆          ┆         │\n",
       "└──────────────┴─────────┴─────────────┴──────────────┴───┴─────────┴─────────┴──────────┴─────────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emotions = pl.concat([pl.read_csv(f\"go_emotions/goemotions_{i}.csv\") for i in [1,2,3]])\n",
    "\n",
    "df_emotions.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdbdd1f4-21e9-4deb-ae28-089c5fadfa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_of_interest = \"excitement\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a32bacdd-33fa-4737-9751-27f14f401539",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_disagree = (\n",
    "    df_emotions\n",
    "    .select(\"text\", \"id\", \"rater_id\", label_of_interest)\n",
    "    .group_by(\"id\", \"text\")\n",
    "    .agg(\n",
    "        n_unique_annot=pl.col(label_of_interest).n_unique(), \n",
    "        n_annot=pl.col(label_of_interest).count(),\n",
    "        rating=pl.col(label_of_interest).mean(),\n",
    "        n_pos=pl.col(label_of_interest).sum()\n",
    "    )\n",
    "    .filter(pl.col(\"n_unique_annot\") != 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3942ea67-d5f4-4f79-82a4-e61d29f94d5a",
   "metadata": {},
   "source": [
    "## Statistics\n",
    "\n",
    "Before diving into the statistics, it helps to remember the difference between an example and an annotation.\n",
    "\n",
    "![](images/annot.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27412ce1-8da2-466e-851e-561012af43ee",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4217 / 58011 individual texts with disagreement.\n",
      "That's about 7.27% of all individual texts that have disagreement.\n",
      "\n",
      "But maybe we can also look at annotations. There are at least 3 per example.\n",
      "But maybe we care a bit more about the positive cases.\n"
     ]
    }
   ],
   "source": [
    "n_disagree = df_disagree.shape[0]\n",
    "n_pos_label = df_emotions.filter(pl.col(label_of_interest) == 1).shape[0]\n",
    "n_pos_disagree = df_disagree.with_columns(pl.col(\"rating\") * pl.col(\"n_annot\")).sum().to_dicts()[0]['n_pos']\n",
    "\n",
    "print(f\"There are {n_disagree} / {df_emotions.group_by('id').count().shape[0]} individual texts with disagreement.\")\n",
    "print(f\"That's about {100 * n_disagree / df_emotions.group_by('id').count().shape[0]:.2f}% of all individual texts that have disagreement.\")\n",
    "print(\"\")\n",
    "print(\"But maybe we can also look at annotations. There are at least 3 per example.\")\n",
    "print(\"But maybe we care a bit more about the positive cases.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6320b2de-55c3-4078-a31d-84d91d320b88",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5629 annotations that indicate excitement in total.\n",
      "Out of these 5629 annotations, 5216 has disagreement.\n",
      "That suggests that 5216 / 5629 = 92.66% of the positive excitement annotations point to a doubtful example.\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {n_pos_label} annotations that indicate {label_of_interest} in total.\")\n",
    "print(f\"Out of these {n_pos_label} annotations, {n_pos_disagree} has disagreement.\")\n",
    "print(f\"That suggests that {n_pos_disagree} / {n_pos_label} = {100 * n_pos_disagree/n_pos_label:.2f}% of the positive {label_of_interest} annotations point to a doubtful example.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216838f4-4ffc-4c1f-b2eb-933ac76e7d78",
   "metadata": {},
   "source": [
    "## Observation \n",
    "\n",
    "These stats may give you pause. And yet ... this dataset is [pretty popular](https://huggingface.co/datasets/go_emotions).\n",
    "\n",
    "## Why? \n",
    "\n",
    "When you explore the samples though, you may start to understand why it is also a hard thing to annotate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ae28d21-700d-4951-ac09-5bc37b292890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Cheers man, will be taking it easy for sure. ', 'rating': 0.3333333333333333, 'n_annot': 3}\n"
     ]
    }
   ],
   "source": [
    "for ex in df_disagree.select(\"text\", \"rating\", \"n_annot\").sample().to_dicts():\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4780868-f584-444c-b965-2f4080c69705",
   "metadata": {},
   "source": [
    "### Towards a Metric \n",
    "\n",
    "We're going to be annotating our own dataset in a bit and we'd like to compare the quality of our own annotations to the quality of GoEmotions. However ... we would prefer to compare apples to apples. \n",
    "\n",
    "So let's introduce a metric that might allow us to compare across datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82953095-f4a2-40e9-803c-8afec6b4d62a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from lazylines import LazyLines\n",
    "import itertools as it\n",
    "\n",
    "def to_pairs(lines, id_key=\"_input_hash\", label_of_interest=\"annot\", annot_id=\"_annotator_id\"):\n",
    "    for ex in lines:\n",
    "        for combo in it.combinations(ex['subset'], 2):\n",
    "            yield {\n",
    "                \"ex\": ex[id_key],\n",
    "                \"u1\": combo[0][annot_id],\n",
    "                \"u2\": combo[1][annot_id],\n",
    "                \"agree\": combo[0][label_of_interest] == combo[1][label_of_interest]\n",
    "            }\n",
    "\n",
    "def calc_observed_agreement(lines):\n",
    "    i = 0\n",
    "    s = 0\n",
    "    for ex in lines:\n",
    "        i += 1\n",
    "        s += ex['agree']\n",
    "    yield s/i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c302989c-ea80-4661-bb50-608504de0881",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 211225/211225 [00:00<00:00, 1241244.33it/s]\n"
     ]
    }
   ],
   "source": [
    "label_of_interest = \"excitement\"\n",
    "\n",
    "# Calculate prob somebody would annotator positive label\n",
    "prob_exp = 1 - df_emotions.select(label_of_interest).mean().to_dicts()[0][label_of_interest]\n",
    "\n",
    "# Calculate how often an example has everyone agree\n",
    "lines = LazyLines(df_emotions.select(\"id\", \"rater_id\", label_of_interest).to_dicts())\n",
    "             \n",
    "prob_obs = (\n",
    "    lines\n",
    "        .progress()\n",
    "        .nest_by(\"id\")\n",
    "        .pipe(to_pairs, label_of_interest=label_of_interest, annot_id=\"rater_id\", id_key=\"id\")\n",
    "        .pipe(calc_observed_agreement)\n",
    "        .collect()[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f92e9ee-25d2-4be5-9284-65bee994eb12",
   "metadata": {},
   "source": [
    "A little bit of theory for agreement statistics. We're about to calculate a number.\n",
    "\n",
    "$$\n",
    "\\kappa \\equiv \\frac{p_o-p_e}{1-p_e}=1-\\frac{1-p_o}{1-p_e}\n",
    "$$\n",
    "\n",
    "The thinking behind this number is that it's best to compare the _expected_ agreement with the _observed_ agreement. This is especially useful in unbalanced label scenarios. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f01b59e-47b2-417f-b4f8-9de9f330a2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability expected: 0.9733506923896319\n",
      "Probability observed: 0.9557999612251536\n",
      "Agreement statistic: -0.6585811316782585\n"
     ]
    }
   ],
   "source": [
    "print(f\"Probability expected: {prob_exp}\")\n",
    "print(f\"Probability observed: {prob_obs}\")\n",
    "print(f\"Agreement statistic: {(prob_obs - prob_exp)/(1 - prob_exp)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f50bbe-baca-4e57-a1a8-c1601fe9c52a",
   "metadata": {},
   "source": [
    "This number is still just a number. But it is something one might track over time and it is also a number that can give you a smell test that something is up. \n",
    "\n",
    "## Our Own Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72f7d6ff-488b-42be-885e-c4f141ccfcdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>text</th><th>_input_hash</th><th>_task_hash</th><th>label</th><th>answer</th><th>_annotator_id</th><th>_session_id</th><th>kind</th><th>annot</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>cat</td><td>cat</td><td>cat</td><td>cat</td><td>cat</td><td>bool</td></tr></thead><tbody><tr><td>&quot;To facilitate …</td><td>-1631564981</td><td>-130688452</td><td>&quot;new-dataset&quot;</td><td>&quot;accept&quot;</td><td>&quot;f96f9733-e216-…</td><td>&quot;7b09a927-88e4-…</td><td>&quot;single&quot;</td><td>true</td></tr><tr><td>&quot;This collectio…</td><td>-1597612878</td><td>-1280357114</td><td>&quot;new-dataset&quot;</td><td>&quot;accept&quot;</td><td>&quot;f96f9733-e216-…</td><td>&quot;7b09a927-88e4-…</td><td>&quot;single&quot;</td><td>true</td></tr><tr><td>&quot;We assume that…</td><td>-1228026693</td><td>2068011284</td><td>&quot;new-dataset&quot;</td><td>&quot;reject&quot;</td><td>&quot;f96f9733-e216-…</td><td>&quot;7b09a927-88e4-…</td><td>&quot;single&quot;</td><td>false</td></tr><tr><td>&quot;To facilitate …</td><td>364583976</td><td>-2053011513</td><td>&quot;new-dataset&quot;</td><td>&quot;accept&quot;</td><td>&quot;f96f9733-e216-…</td><td>&quot;7b09a927-88e4-…</td><td>&quot;single&quot;</td><td>true</td></tr><tr><td>&quot;To fully unloc…</td><td>-1833406195</td><td>-332649941</td><td>&quot;new-dataset&quot;</td><td>&quot;accept&quot;</td><td>&quot;f96f9733-e216-…</td><td>&quot;7b09a927-88e4-…</td><td>&quot;single&quot;</td><td>true</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 9)\n",
       "┌────────────┬────────────┬────────────┬────────────┬───┬────────────┬────────────┬────────┬───────┐\n",
       "│ text       ┆ _input_has ┆ _task_hash ┆ label      ┆ … ┆ _annotator ┆ _session_i ┆ kind   ┆ annot │\n",
       "│ ---        ┆ h          ┆ ---        ┆ ---        ┆   ┆ _id        ┆ d          ┆ ---    ┆ ---   │\n",
       "│ str        ┆ ---        ┆ i64        ┆ cat        ┆   ┆ ---        ┆ ---        ┆ cat    ┆ bool  │\n",
       "│            ┆ i64        ┆            ┆            ┆   ┆ cat        ┆ cat        ┆        ┆       │\n",
       "╞════════════╪════════════╪════════════╪════════════╪═══╪════════════╪════════════╪════════╪═══════╡\n",
       "│ To         ┆ -163156498 ┆ -130688452 ┆ new-datase ┆ … ┆ f96f9733-e ┆ 7b09a927-8 ┆ single ┆ true  │\n",
       "│ facilitate ┆ 1          ┆            ┆ t          ┆   ┆ 216-4362-9 ┆ 8e4-4bd5-b ┆        ┆       │\n",
       "│ research   ┆            ┆            ┆            ┆   ┆ e68-ca314f ┆ abd-9dc23e ┆        ┆       │\n",
       "│ in this f… ┆            ┆            ┆            ┆   ┆ 18…        ┆ a7…        ┆        ┆       │\n",
       "│ This       ┆ -159761287 ┆ -128035711 ┆ new-datase ┆ … ┆ f96f9733-e ┆ 7b09a927-8 ┆ single ┆ true  │\n",
       "│ collection ┆ 8          ┆ 4          ┆ t          ┆   ┆ 216-4362-9 ┆ 8e4-4bd5-b ┆        ┆       │\n",
       "│ includes a ┆            ┆            ┆            ┆   ┆ e68-ca314f ┆ abd-9dc23e ┆        ┆       │\n",
       "│ subse…     ┆            ┆            ┆            ┆   ┆ 18…        ┆ a7…        ┆        ┆       │\n",
       "│ We assume  ┆ -122802669 ┆ 2068011284 ┆ new-datase ┆ … ┆ f96f9733-e ┆ 7b09a927-8 ┆ single ┆ false │\n",
       "│ that the   ┆ 3          ┆            ┆ t          ┆   ┆ 216-4362-9 ┆ 8e4-4bd5-b ┆        ┆       │\n",
       "│ data       ┆            ┆            ┆            ┆   ┆ e68-ca314f ┆ abd-9dc23e ┆        ┆       │\n",
       "│ manifold…  ┆            ┆            ┆            ┆   ┆ 18…        ┆ a7…        ┆        ┆       │\n",
       "│ To         ┆ 364583976  ┆ -205301151 ┆ new-datase ┆ … ┆ f96f9733-e ┆ 7b09a927-8 ┆ single ┆ true  │\n",
       "│ facilitate ┆            ┆ 3          ┆ t          ┆   ┆ 216-4362-9 ┆ 8e4-4bd5-b ┆        ┆       │\n",
       "│ the develo ┆            ┆            ┆            ┆   ┆ e68-ca314f ┆ abd-9dc23e ┆        ┆       │\n",
       "│ pment of…  ┆            ┆            ┆            ┆   ┆ 18…        ┆ a7…        ┆        ┆       │\n",
       "│ To fully   ┆ -183340619 ┆ -332649941 ┆ new-datase ┆ … ┆ f96f9733-e ┆ 7b09a927-8 ┆ single ┆ true  │\n",
       "│ unlock     ┆ 5          ┆            ┆ t          ┆   ┆ 216-4362-9 ┆ 8e4-4bd5-b ┆        ┆       │\n",
       "│ model capa ┆            ┆            ┆            ┆   ┆ e68-ca314f ┆ abd-9dc23e ┆        ┆       │\n",
       "│ biliti…    ┆            ┆            ┆            ┆   ┆ 18…        ┆ a7…        ┆        ┆       │\n",
       "└────────────┴────────────┴────────────┴────────────┴───┴────────────┴────────────┴────────┴───────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cast_to_cat(dataf, *cols):\n",
    "    return dataf.with_columns(**{c: pl.col(c).cast(pl.Categorical) for c in cols})\n",
    "\n",
    "df = pl.read_ndjson(\"cleaned.jsonl\").pipe(cast_to_cat, \"label\", \"answer\", \"_annotator_id\", \"_session_id\", \"kind\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b33291-5681-4a55-83fd-5bab2a0348cd",
   "metadata": {},
   "source": [
    "## Do you agree with yourself?\n",
    "\n",
    "This is a query that allows you to compare a single annotator across annotation interfaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "881837ac-8399-4c1d-8718-47f27ccec911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>single</th><th>multi</th><th>count</th></tr><tr><td>u32</td><td>u32</td><td>u32</td></tr></thead><tbody><tr><td>0</td><td>0</td><td>2</td></tr><tr><td>1</td><td>0</td><td>3</td></tr><tr><td>0</td><td>1</td><td>5</td></tr><tr><td>1</td><td>1</td><td>4</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 3)\n",
       "┌────────┬───────┬───────┐\n",
       "│ single ┆ multi ┆ count │\n",
       "│ ---    ┆ ---   ┆ ---   │\n",
       "│ u32    ┆ u32   ┆ u32   │\n",
       "╞════════╪═══════╪═══════╡\n",
       "│ 0      ┆ 0     ┆ 2     │\n",
       "│ 1      ┆ 0     ┆ 3     │\n",
       "│ 0      ┆ 1     ┆ 5     │\n",
       "│ 1      ┆ 1     ┆ 4     │\n",
       "└────────┴───────┴───────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = \"new-dataset\"\n",
    "annot_id = \"f96f9733-e216-4362-9e68-ca314f186b5e\"\n",
    "\n",
    "(\n",
    "    df\n",
    "        .filter(pl.col(\"label\") == label)\n",
    "        .filter(pl.col(\"_annotator_id\") == annot_id)\n",
    "        .pivot(values=\"annot\", index=\"_input_hash\", columns=\"kind\", aggregate_function=\"sum\")\n",
    "        .filter(\n",
    "            pl.col(\"single\").is_not_null() & pl.col(\"multi\").is_not_null()\n",
    "        )\n",
    "        .group_by(\"single\", \"multi\")\n",
    "        .count()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc709b9d-96b1-4266-9845-881b18b2dc29",
   "metadata": {},
   "source": [
    "## Do annotators agree with eachother?\n",
    "\n",
    "Let's first check the examples that differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64f0f128-27f1-4552-a801-1ca8a4c05bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (20, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>_input_hash</th><th>n_unique_annot</th><th>n_annot</th><th>rating</th></tr><tr><td>i64</td><td>u32</td><td>u32</td><td>f64</td></tr></thead><tbody><tr><td>1128546023</td><td>2</td><td>2</td><td>0.5</td></tr><tr><td>-1208466695</td><td>2</td><td>2</td><td>1.0</td></tr><tr><td>-664389724</td><td>2</td><td>2</td><td>0.5</td></tr><tr><td>-1293250435</td><td>2</td><td>2</td><td>0.5</td></tr><tr><td>-310040368</td><td>2</td><td>2</td><td>0.5</td></tr><tr><td>-1150096620</td><td>2</td><td>2</td><td>0.5</td></tr><tr><td>1985152956</td><td>2</td><td>2</td><td>1.0</td></tr><tr><td>-262199974</td><td>2</td><td>2</td><td>0.5</td></tr><tr><td>1002264393</td><td>2</td><td>2</td><td>0.5</td></tr><tr><td>72276985</td><td>2</td><td>2</td><td>0.0</td></tr><tr><td>-2086104188</td><td>2</td><td>2</td><td>0.5</td></tr><tr><td>-551595170</td><td>2</td><td>2</td><td>0.5</td></tr><tr><td>1577109932</td><td>2</td><td>2</td><td>0.5</td></tr><tr><td>-91203428</td><td>2</td><td>2</td><td>0.5</td></tr><tr><td>1758901217</td><td>2</td><td>2</td><td>0.5</td></tr><tr><td>-1341409254</td><td>2</td><td>2</td><td>0.5</td></tr><tr><td>-1325424758</td><td>2</td><td>2</td><td>0.5</td></tr><tr><td>1394778328</td><td>2</td><td>2</td><td>0.0</td></tr><tr><td>-1635053316</td><td>2</td><td>2</td><td>1.0</td></tr><tr><td>-101513363</td><td>2</td><td>2</td><td>0.5</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (20, 4)\n",
       "┌─────────────┬────────────────┬─────────┬────────┐\n",
       "│ _input_hash ┆ n_unique_annot ┆ n_annot ┆ rating │\n",
       "│ ---         ┆ ---            ┆ ---     ┆ ---    │\n",
       "│ i64         ┆ u32            ┆ u32     ┆ f64    │\n",
       "╞═════════════╪════════════════╪═════════╪════════╡\n",
       "│ 1128546023  ┆ 2              ┆ 2       ┆ 0.5    │\n",
       "│ -1208466695 ┆ 2              ┆ 2       ┆ 1.0    │\n",
       "│ -664389724  ┆ 2              ┆ 2       ┆ 0.5    │\n",
       "│ -1293250435 ┆ 2              ┆ 2       ┆ 0.5    │\n",
       "│ …           ┆ …              ┆ …       ┆ …      │\n",
       "│ -1325424758 ┆ 2              ┆ 2       ┆ 0.5    │\n",
       "│ 1394778328  ┆ 2              ┆ 2       ┆ 0.0    │\n",
       "│ -1635053316 ┆ 2              ┆ 2       ┆ 1.0    │\n",
       "│ -101513363  ┆ 2              ┆ 2       ┆ 0.5    │\n",
       "└─────────────┴────────────────┴─────────┴────────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = \"new-dataset\"\n",
    "kind = \"single\" \n",
    "\n",
    "(\n",
    "    df\n",
    "        .filter(pl.col(\"label\") == label)\n",
    "        .filter(pl.col(\"kind\") == kind)\n",
    "        .group_by(\"_input_hash\")\n",
    "        .agg(\n",
    "            n_unique_annot=pl.col(\"annot\").n_unique(), \n",
    "            n_annot=pl.col(\"annot\").count(),\n",
    "            rating=pl.col(\"annot\").mean()\n",
    "        )\n",
    "        .filter(pl.col(\"n_unique_annot\") != 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a5f636-5158-4d5a-b00d-172eb30ef168",
   "metadata": {},
   "source": [
    "You can pick an example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dab2fdc8-5673-4657-bbe9-da27b2cfdd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on a modified version of the EntailmentBank dataset and a new dataset called Everyday Norms: Why Not? show that abductive generation with validation can recover premises across in- and out-of-domain settings\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>_annotator_id</th><th>annot</th></tr><tr><td>cat</td><td>bool</td></tr></thead><tbody><tr><td>&quot;f96f9733-e216-…</td><td>false</td></tr><tr><td>&quot;38966de5-008d-…</td><td>true</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "┌───────────────────────────────────┬───────┐\n",
       "│ _annotator_id                     ┆ annot │\n",
       "│ ---                               ┆ ---   │\n",
       "│ cat                               ┆ bool  │\n",
       "╞═══════════════════════════════════╪═══════╡\n",
       "│ f96f9733-e216-4362-9e68-ca314f18… ┆ false │\n",
       "│ 38966de5-008d-40a2-aa12-0b51c18c… ┆ true  │\n",
       "└───────────────────────────────────┴───────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_hash = -2086104188\n",
    "\n",
    "print(df.filter(pl.col(\"_input_hash\") == input_hash).head(1).to_dict(as_series=False)['text'][0])\n",
    "\n",
    "(\n",
    "    df\n",
    "        .filter(pl.col(\"label\") == label)\n",
    "        .filter(pl.col(\"kind\") == kind)\n",
    "        .filter(pl.col(\"_input_hash\") == input_hash)\n",
    "        .select(\"_annotator_id\", \"annot\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d930d896-c504-4fff-852e-e5b62a7c18f4",
   "metadata": {},
   "source": [
    "Also here we can try to calculate annotator agreement statistics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04133e79-ce0e-4539-a994-af3e2659dce4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_singles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_singles\u001b[49m\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_singles' is not defined"
     ]
    }
   ],
   "source": [
    "df_singles.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cd3899-3afb-444d-81c4-da7fc1cbe88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_singles = df.filter(pl.col(\"label\") == \"new-dataset\").filter(pl.col(\"kind\") == \"single\")\n",
    "\n",
    "# Calculate prob somebody would annotator positive label\n",
    "prob_exp = 1 - df_singles.select(\"annot\").mean().to_dicts()[0][\"annot\"]\n",
    "\n",
    "# Calculate how often an example has everyone agree\n",
    "lines = LazyLines(df_singles.select(\"_input_hash\", \"_annotator_id\", \"annot\").to_dicts())\n",
    "             \n",
    "prob_obs = (\n",
    "    lines\n",
    "        .progress()\n",
    "        .nest_by(\"_input_hash\")\n",
    "        .pipe(to_pairs)\n",
    "        .pipe(calc_observed_agreement)\n",
    "        .collect()[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ce2657-16aa-49d7-a1eb-4caecf9ab5f1",
   "metadata": {},
   "source": [
    "This number should be much better than GoEmotions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3393d8eb-2780-4e81-9992-f357cd556972",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Probability expected: {prob_exp}\")\n",
    "print(f\"Probability observed: {prob_obs}\")\n",
    "print(f\"Agreement statistic: {(prob_obs - prob_exp)/(1 - prob_exp)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
